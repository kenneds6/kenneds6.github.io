---
title: "Overcoming Adversarial Attacks for Hunam-in-the-Loop Applications"
collection: publications
permalink: 
excerpt: 'Including human analysis has the potential to positively affect the robustness of Deep Neural Networks and is relatively unexplored in the Adversarial Machine Learning literature. Neural network visual explanation maps have been shown to
be prone to adversarial attacks. Further research
is needed in order to select robust visualizations
of explanations for the image analyst to evaluate a given model. These factors greatly impact
Human-In-The-Loop (HITL) evaluation tools due
to their reliance on adversarial images, including
explanation maps and measurements of robustness. We believe models of human visual attention may improve interpretability and robustness
of human-machine imagery analysis systems. Our
challenge remains, how can HITL evaluation be
robust in this adversarial landscape?
'
date: 2022-07-20
venue: 'ICML 22 AdvML Workshop'
paperurl: 'https://advml-frontier.github.io/pdf/9/CameraReady/ICML_AdvML_Workshop_2022.pdf'
citation: 'McCoppin, R., Kennedy, M., Lukyanenko, P., & Kennedy, SM. (2022). Overcoming Adversarial Attacks for Hunam-in-the-Loop Applications. Proceedings of the 39th International Conference on Machine Learning, New Frontiers in Adversarial Machine Learning Workshop. Baltimore, Maryland.'
---
Paper Abstract: Including human analysis has the potential to positively affect the robustness of Deep Neural Networks and is relatively unexplored in the Adversarial Machine Learning literature. Neural network visual explanation maps have been shown to
be prone to adversarial attacks. Further research
is needed in order to select robust visualizations
of explanations for the image analyst to evaluate a given model. These factors greatly impact
Human-In-The-Loop (HITL) evaluation tools due
to their reliance on adversarial images, including
explanation maps and measurements of robustness. We believe models of human visual attention may improve interpretability and robustness
of human-machine imagery analysis systems. Our
challenge remains, how can HITL evaluation be
robust in this adversarial landscape?


[Download paper here](http://kenneds6.github.io/files/ICML_AdvML_Workshop_2022.pdf)

Recommended citation: McCoppin, R., Kennedy, M., Lukyanenko, P., & Kennedy, SM. (2022). Overcoming Adversarial Attacks for Hunam-in-the-Loop Applications. Proceedings of the 39th International Conference on Machine Learning, New Frontiers in Adversarial Machine Learning Workshop. Baltimore, Maryland.